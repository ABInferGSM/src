{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.3621e+00, -1.3835e+00,  2.0876e+00,  2.2452e+00, -5.3978e+00,\n",
       "         -2.7148e+00,  5.1779e+00, -3.2429e+00,  3.1859e+00,  2.1629e+00],\n",
       "        [-1.3835e+00,  1.1233e+00, -1.3666e+00, -4.0351e-01,  8.2396e-01,\n",
       "          7.5615e-01, -9.4841e-01, -3.8923e-01, -6.4075e-01, -5.6573e-01],\n",
       "        [ 2.0876e+00, -1.3666e+00,  2.8102e+00,  6.6836e-01, -2.1607e+00,\n",
       "         -3.7723e-01,  2.6955e+00,  5.8294e-03,  2.1232e+00,  8.1947e-01],\n",
       "        [ 2.2452e+00, -4.0351e-01,  6.6836e-01,  6.7725e+00, -3.1622e+00,\n",
       "         -1.5331e+00,  4.1728e+00, -1.0258e+00,  2.4556e+00,  1.9869e-01],\n",
       "        [-5.3978e+00,  8.2396e-01, -2.1607e+00, -3.1622e+00,  8.7091e+00,\n",
       "          3.0445e+00, -7.1515e+00,  5.6624e+00, -4.7918e+00, -2.2579e+00],\n",
       "        [-2.7148e+00,  7.5615e-01, -3.7723e-01, -1.5331e+00,  3.0445e+00,\n",
       "          2.3264e+00, -2.7092e+00,  2.3217e+00, -1.3182e+00, -1.4961e+00],\n",
       "        [ 5.1779e+00, -9.4841e-01,  2.6955e+00,  4.1728e+00, -7.1515e+00,\n",
       "         -2.7092e+00,  8.4633e+00, -5.0264e+00,  5.2339e+00,  2.8545e+00],\n",
       "        [-3.2429e+00, -3.8923e-01,  5.8294e-03, -1.0258e+00,  5.6624e+00,\n",
       "          2.3217e+00, -5.0264e+00,  5.6905e+00, -2.8898e+00, -2.2083e+00],\n",
       "        [ 3.1859e+00, -6.4075e-01,  2.1232e+00,  2.4556e+00, -4.7918e+00,\n",
       "         -1.3182e+00,  5.2339e+00, -2.8898e+00,  3.5153e+00,  1.4935e+00],\n",
       "        [ 2.1629e+00, -5.6573e-01,  8.1947e-01,  1.9869e-01, -2.2579e+00,\n",
       "         -1.4961e+00,  2.8545e+00, -2.2083e+00,  1.4935e+00,  1.7024e+00]],\n",
       "       dtype=torch.float64, grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A0 = np.random.randn(10,5)\n",
    "#A0 = (A0.transpose()).dot(A0)\n",
    "A0 = torch.from_numpy(A0)\n",
    "A0.requires_grad = True\n",
    "A = torch.mm(A0,A0.t())\n",
    "A\n",
    "#A.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gpytorch\n",
    "\n",
    "def psd_safe_cholesky(A, upper=False, out=None, jitter=None):\n",
    "    \"\"\"Compute the Cholesky decomposition of A. If A is only p.s.d, add a small jitter to the diagonal.\n",
    "    Args:\n",
    "        :attr:`A` (Tensor):\n",
    "            The tensor to compute the Cholesky decomposition of\n",
    "        :attr:`upper` (bool, optional):\n",
    "            See torch.cholesky\n",
    "        :attr:`out` (Tensor, optional):\n",
    "            See torch.cholesky\n",
    "        :attr:`jitter` (float, optional):\n",
    "            The jitter to add to the diagonal of A in case A is only p.s.d. If omitted, chosen\n",
    "            as 1e-6 (float) or 1e-8 (double)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        L = torch.cholesky(A, upper=upper, out=out)\n",
    "        return L\n",
    "    except RuntimeError as e:\n",
    "        isnan = torch.isnan(A)\n",
    "        if isnan.any():\n",
    "            raise NanError(\n",
    "                f\"cholesky_cpu: {isnan.sum().item()} of {A.numel()} elements of the {A.shape} tensor are NaN.\"\n",
    "            )\n",
    "\n",
    "        if jitter is None:\n",
    "            jitter = 1e-6 if A.dtype == torch.float32 else 1e-8\n",
    "        Aprime = A.clone()\n",
    "        jitter_prev = 0\n",
    "        for i in range(3):\n",
    "            jitter_new = jitter * (10 ** i)\n",
    "            Aprime.diagonal(dim1=-2, dim2=-1).add_(jitter_new - jitter_prev)\n",
    "            jitter_prev = jitter_new\n",
    "            try:\n",
    "                L = torch.cholesky(Aprime, upper=upper, out=out)\n",
    "                #warnings.warn(f\"A not p.d., added jitter of {jitter_new} to the diagonal\", NumericalWarning)\n",
    "                return L\n",
    "            except RuntimeError:\n",
    "                continue\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace_A = ((torch.cholesky(A)).diag().log()).sum()\n",
    "# trace_A.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_det(L):\n",
    "    return (L.diag().log()).sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = psd_safe_cholesky(A)\n",
    "y = log_det(L)\n",
    "y.backward()\n",
    "#A0.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.3621e+00, -1.3835e+00,  2.0876e+00,  2.2452e+00, -5.3978e+00,\n",
       "         -2.7148e+00,  5.1779e+00, -3.2429e+00,  3.1859e+00,  2.1629e+00],\n",
       "        [-1.3835e+00,  1.1233e+00, -1.3666e+00, -4.0351e-01,  8.2396e-01,\n",
       "          7.5615e-01, -9.4841e-01, -3.8923e-01, -6.4075e-01, -5.6573e-01],\n",
       "        [ 2.0876e+00, -1.3666e+00,  2.8102e+00,  6.6836e-01, -2.1607e+00,\n",
       "         -3.7723e-01,  2.6955e+00,  5.8294e-03,  2.1232e+00,  8.1947e-01],\n",
       "        [ 2.2452e+00, -4.0351e-01,  6.6836e-01,  6.7725e+00, -3.1622e+00,\n",
       "         -1.5331e+00,  4.1728e+00, -1.0258e+00,  2.4556e+00,  1.9869e-01],\n",
       "        [-5.3978e+00,  8.2396e-01, -2.1607e+00, -3.1622e+00,  8.7091e+00,\n",
       "          3.0445e+00, -7.1515e+00,  5.6624e+00, -4.7918e+00, -2.2579e+00],\n",
       "        [-2.7148e+00,  7.5615e-01, -3.7723e-01, -1.5331e+00,  3.0445e+00,\n",
       "          2.3264e+00, -2.7092e+00,  2.3217e+00, -1.3182e+00, -1.4961e+00],\n",
       "        [ 5.1779e+00, -9.4841e-01,  2.6955e+00,  4.1728e+00, -7.1515e+00,\n",
       "         -2.7092e+00,  8.4633e+00, -5.0264e+00,  5.2339e+00,  2.8545e+00],\n",
       "        [-3.2429e+00, -3.8923e-01,  5.8294e-03, -1.0258e+00,  5.6624e+00,\n",
       "          2.3217e+00, -5.0264e+00,  5.6905e+00, -2.8898e+00, -2.2083e+00],\n",
       "        [ 3.1859e+00, -6.4075e-01,  2.1232e+00,  2.4556e+00, -4.7918e+00,\n",
       "         -1.3182e+00,  5.2339e+00, -2.8898e+00,  3.5153e+00,  1.4935e+00],\n",
       "        [ 2.1629e+00, -5.6573e-01,  8.1947e-01,  1.9869e-01, -2.2579e+00,\n",
       "         -1.4961e+00,  2.8545e+00, -2.2083e+00,  1.4935e+00,  1.7024e+00]],\n",
       "       dtype=torch.float64, grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,v = torch.eig(A,eigenvectors=True)\n",
    "\n",
    "\n",
    "# L = torch.mm(P_cuda,P_cuda.t())\n",
    "# w,v = torch.eig(L,eigenvectors=True),\n",
    "# v.mul_(torch.sqrt(torch.sqrt(1./w[:,0])))\n",
    "# U = torch.mm(v,v.t())\n",
    "# P_cuda = torch.mm(U,P_cuda)\n",
    "# print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
